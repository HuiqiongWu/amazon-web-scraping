{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff06f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.3.0-py3-none-any.whl (981 kB)\n",
      "\u001b[K     |████████████████████████████████| 981 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trio~=0.17\n",
      "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
      "\u001b[K     |████████████████████████████████| 358 kB 52.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: idna in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: sniffio in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: cffi>=1.12 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.20)\n",
      "Requirement already satisfied: six>=1.5.2 in /Users/huiqiongwu/opt/anaconda3/lib/python3.9/site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "\u001b[K     |████████████████████████████████| 58 kB 23.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: outcome, h11, wsproto, trio, trio-websocket, selenium\n",
      "Successfully installed h11-0.13.0 outcome-1.2.0 selenium-4.3.0 trio-0.21.0 trio-websocket-0.9.2 wsproto-1.1.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fd5b471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mysql-connector-python-rf\n",
      "  Downloading mysql-connector-python-rf-2.2.2.tar.gz (11.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.9 MB 3.9 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: mysql-connector-python-rf\n",
      "  Building wheel for mysql-connector-python-rf (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for mysql-connector-python-rf: filename=mysql_connector_python_rf-2.2.2-cp39-cp39-macosx_10_9_x86_64.whl size=249480 sha256=e7a16ce71ccc70509cec735fcc0a0893d6f290048977dab03feaa70243e3cc4b\n",
      "  Stored in directory: /Users/huiqiongwu/Library/Caches/pip/wheels/64/06/5b/ef9543936a3f5de15b02775b6ae548a09f3ed2319d20342771\n",
      "Successfully built mysql-connector-python-rf\n",
      "Installing collected packages: mysql-connector-python-rf\n",
      "Successfully installed mysql-connector-python-rf-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mysql-connector-python-rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dfa9633",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import time\n",
    "from selenium import webdriver\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mysql.connector\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7623b29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/51.0.2704.103 Safari/537.36',\n",
    "          'Accept-Language': 'en-US, en;q-0.5'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea286c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.amazon.com/s?k=smart+tv'\n",
    "prime_url = ''\n",
    "non_prime_url = ''\n",
    "\n",
    "for i in range(1, 10):\n",
    "    ## navigate to the ith page\n",
    "    responsei = requests.get(URL + \"&page=\" + str(i), headers = headers)\n",
    "    soupi = BeautifulSoup(responsei.content, 'html.parser')\n",
    "    \n",
    "    ## Find the part of code containing prime information and the URL of each item\n",
    "    link = soupi.find_all('div', {'class': 's-result-item', 'data-component-type': 's-search-result'})\n",
    "   \n",
    "    for j in range(0, len(link)):\n",
    "        ## Find the sponsored items\n",
    "        item = link[j].find_all('i', class_ = \"a-icon\")\n",
    "        ## Get the URL of each item\n",
    "        item_url = link[j].h2.a['href']\n",
    "        ## Separate sponsored and non-sponsored items\n",
    "        if len(item) == 0:\n",
    "            non_prime_url = non_prime_url + '\\n' + item_url\n",
    "        else:\n",
    "            prime_url = prime_url + '\\n' + item_url\n",
    "    \n",
    "    ## Set a 2-second pause before going to the next page\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754be5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the URLs\n",
    "with open('prime.txt', 'w') as file:\n",
    "    file.write(prime_url.lstrip())\n",
    "with open('non_prime.txt', 'w') as file:\n",
    "    file.write(non_prime_url.lstrip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6913e53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create two folders\n",
    "path1 = 'prime'\n",
    "os.mkdir(path1)\n",
    "path2 = 'non-prime'\n",
    "os.mkdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d93f9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open the files\n",
    "read_prime = open('prime.txt', 'r').read()\n",
    "read_non_prime = open('non_prime.txt', 'r').read()\n",
    "## Split the strings\n",
    "prime_url_split = read_prime.split('\\n')\n",
    "non_prime_url_split = read_non_prime.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f81984c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Download each prime item's URL into folder 'prime'\n",
    "for item in range(0, len(prime_url_split)):\n",
    "    URL = prime_url_split[item]\n",
    "    response = requests.get('https://www.amazon.com' + URL, headers = headers)\n",
    "    iid = str(item)\n",
    "    \n",
    "    with open(os.path.join(os.getcwd() + '/prime/' + iid + '.html'), 'w', encoding='utf8') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    ## Set a 2-second pause before going to the next item\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4105826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in range(0, len(non_prime_url_split)):\n",
    "    URL = non_prime_url_split[item]\n",
    "    response = requests.get('https://www.amazon.com' + URL, headers = headers)\n",
    "    iid = str(item)\n",
    "    \n",
    "    with open(os.path.join(os.getcwd() + '/non-prime/' + iid + '.html'), 'w', encoding='utf8') as file:\n",
    "        file.write(response.text)\n",
    "    \n",
    "    ## Set a 2-second pause before going to the next item\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c2340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through prime pages\n",
    "pages = os.listdir('./prime')\n",
    "prime_df = pd.DataFrame(columns = ['seller_name', 'seller_score', 'item_price', 'list_price','num_reviews', 'title'])\n",
    "i = 0\n",
    "\n",
    "for page in pages:\n",
    "    readfile = open(os.path.join(os.getcwd() + '/prime', page), 'r',encoding='utf-8').read()\n",
    "    soup = BeautifulSoup(readfile, 'html.parser')\n",
    "    \n",
    "    ## identify prime or non-prime item\n",
    "    \n",
    "    ## seller name\n",
    "    try:\n",
    "        find_seller = soup.find('div', id='bylineInfo_feature_div') ## selector command\n",
    "        seller_name = find_seller.find('a', id='bylineInfo').get_text() ## selector command\n",
    "    except:\n",
    "        seller_name = None\n",
    "    \n",
    "    ## seller score\n",
    "    try:\n",
    "        seller_score = pd.to_numeric(find_seller.find('span', class_ = 'a-icon-alt').get_text()) ## selector command\n",
    "    except:\n",
    "        seller_score = None\n",
    "    \n",
    "    ## item price\n",
    "    try:\n",
    "        try:\n",
    "            find_price = soup.find('span', class_='a-price aok-align-cnter reinventPricePriceToPayMargin pricetToPay').get_text() ## selector command\n",
    "            item_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', find_price))\n",
    "\n",
    "        except:\n",
    "            find_price = soup.find('span', class_='a-price a-text-price a-size-medium apexPriceToPay a-offscreen').get_text() ## selector command\n",
    "            item_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', find_price)) \n",
    "           \n",
    "    except:\n",
    "        item_price = None\n",
    "    \n",
    "    ## list price\n",
    "\n",
    "    try:\n",
    "        find_list_price = soup.find('div', class_='a-section a-spacing-small aok-align-center') ## selector command\n",
    "        price_list = find_list_price.find('span', class_='a-offscreen').get_text()\n",
    "        list_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', price_list))\n",
    "\n",
    "    except:\n",
    "        list_price = None\n",
    "    \n",
    "    ## number of reviews\n",
    "    try:\n",
    "        find_item = soup.find('div', id = 'centerlCol') ## selector command\n",
    "        reviews = find_item.find('span', id = 'acrCustomerReviewText').get_text() ## selector command\n",
    "        reviews_num = re.sub(r'([,\\d]+) sold', r'\\1', reviews)\n",
    "        num_reviews = pd.to_numeric(re.sub(r',', r'', reviews_num))\n",
    "    except:\n",
    "        num_reviews = None\n",
    "    \n",
    "    ## title\n",
    "    try:\n",
    "        title_text = soup.find('h1', id = 'title').get_text() ## selector command\n",
    "        title = re.sub(r'Details about  \\xa0', r'', title_text)\n",
    "    except:\n",
    "        title = None\n",
    "    \n",
    "        \n",
    "    ## condition\n",
    "    try:\n",
    "        condition = soup.find('div', id = 'vi-itm-cond').get_text() ## selector command\n",
    "    except:\n",
    "        condition = None\n",
    "    \n",
    "    ## Save to data frame\n",
    "    prime_df.loc[i] = [seller_name, seller_score, item_price, list_price,num_reviews, title]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36202388",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loop through non-prime pages\n",
    "pages = os.listdir('./non_prime')\n",
    "nonprime_df = pd.DataFrame(columns = ['seller_name', 'seller_score', 'item_price', 'list price','num_reviews', 'title'])\n",
    "i = 0\n",
    "\n",
    "for page in pages:\n",
    "    readfile = open(os.path.join(os.getcwd() + '/non_prime', page), 'r').read()\n",
    "    soup = BeautifulSoup(readfile, 'html.parser')\n",
    "    \n",
    "    ## identify prime or non-prime item\n",
    "    \n",
    "    ## seller name\n",
    "    try:\n",
    "        find_seller = soup.find('div', id='bylineInfo_feature_div') ## selector command\n",
    "        seller_name = find_seller.find('a', id='bylineInfo').get_text() ## selector command\n",
    "    except:\n",
    "        seller_name = None\n",
    "    \n",
    "    ## seller score\n",
    "    try:\n",
    "        seller_score = pd.to_numeric(find_seller.find('span', class_ = 'a-icon-alt').get_text()) ## selector command\n",
    "    except:\n",
    "        seller_score = None\n",
    "    \n",
    "    ## item price\n",
    "    try:\n",
    "        try:\n",
    "            find_price = soup.find('span', class_='a-price aok-align-cnter reinventPricePriceToPayMargin pricetToPay').get_text() ## selector command\n",
    "            item_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', find_price))\n",
    "\n",
    "        except:\n",
    "            find_price = soup.find('span', class_='a-price a-text-price a-size-medium apexPriceToPay a-offscreen').get_text() ## selector command\n",
    "            item_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', find_price)) \n",
    "           \n",
    "    except:\n",
    "        item_price = None\n",
    "    \n",
    "    ## list price\n",
    "\n",
    "    try:\n",
    "        find_list_price = soup.find('div', class_='a-section a-spacing-small aok-align-center') ## selector command\n",
    "        price_list = find_list_price.find('span', class_='a-offscreen').get_text()\n",
    "        list_price = pd.to_numeric(re.sub(r'.*\\$([.\\d]+).*', r'\\1', price_list))\n",
    "\n",
    "    except:\n",
    "        list_price = None\n",
    "    \n",
    "    ## number of reviews\n",
    "    try:\n",
    "        find_item = soup.find('div', id = 'centerlCol') ## selector command\n",
    "        reviews = find_item.find('span', id = 'acrCustomerReviewText').get_text() ## selector command\n",
    "        reviews_num = re.sub(r'([,\\d]+) sold', r'\\1', reviews)\n",
    "        num_reviews = pd.to_numeric(re.sub(r',', r'', reviews_num))\n",
    "    except:\n",
    "        num_reviews = None\n",
    "    \n",
    "    ## title\n",
    "    try:\n",
    "        title_text = soup.find('h1', id = 'title').get_text() ## selector command\n",
    "        title = re.sub(r'Details about  \\xa0', r'', title_text)\n",
    "    except:\n",
    "        title = None\n",
    "    \n",
    "        \n",
    "    ## condition\n",
    "    try:\n",
    "        condition = soup.find('div', id = 'vi-itm-cond').get_text() ## selector command\n",
    "    except:\n",
    "        condition = None\n",
    "    \n",
    "    ## Save to data frame\n",
    "    nonprime_df.loc[i] = [seller_name, seller_score, item_price, list_price,num_reviews, title]\n",
    "    i = i + 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
